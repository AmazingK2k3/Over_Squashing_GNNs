{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LD1IpgDTrdO"
      },
      "outputs": [],
      "source": [
        "pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPvLjfW0T0N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(data)\n",
        "train_size = int(0.8 * len(data))\n",
        "val_size = int(0.1 * len(data))\n",
        "test_size = len(data) - train_size - val_size\n",
        "train_data = data[:train_size]\n",
        "val_data = data[train_size:train_size + val_size]\n",
        "test_data = data[train_size + val_size:]"
      ],
      "metadata": {
        "id": "ZpH109sMUEwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train_size, Test_Size, Val_size: {train_size}, {test_size}, {val_size}\")"
      ],
      "metadata": {
        "id": "aC42kuKRUEto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda ' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "rRiIwB50UHJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loader(batch_size):\n",
        "  train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "  val_loader = DataLoader(val_data, batch_size = batch_size, shuffle = True)\n",
        "  test_loader = DataLoader(test_data, batch_size = 1 , shuffle = True)\n",
        "\n",
        "  return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "7qgn3sHnUHIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_node_features is the number of node features.\n",
        "\n",
        "from binascii import a2b_hex\n",
        "\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, dim_h):\n",
        "        super().__init__()\n",
        "        self.sage1 = SAGEConv(num_node_features, dim_h)\n",
        "        self.sage2 = SAGEConv(dim_h, dim_h//2)\n",
        "        self.sage3 = SAGEConv(dim_h//2, dim_h//4)\n",
        "        self.lin = Linear((dim_h//4), 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        import itertools\n",
        "        edges = list(itertools.permutations(range(18),2))\n",
        "        full_adj = torch.tensor(edges,dtype = torch.long).t().contiguous().to(device)\n",
        "\n",
        "        h1 = self.sage1(x, edge_index)\n",
        "        h = F.elu(h1)\n",
        "        h = F.dropout(h, p=0.5, training=self.training)\n",
        "        h2 = self.sage2(h, edge_index)\n",
        "        h = F.elu(h2)\n",
        "        h = F.dropout(h, p=0.5, training=self.training)\n",
        "        h3 = self.sage3(h,full_adj)\n",
        "\n",
        "\n",
        "        a1 = global_mean_pool(h1,batch)\n",
        "        m1 = global_max_pool(h1,batch)\n",
        "        a2 = global_mean_pool(h2,batch)\n",
        "        m2 = global_max_pool(h2,batch)\n",
        "\n",
        "        #h = torch.cat((a1,a2), dim = 1)\n",
        "        h = global_mean_pool(h3, batch)\n",
        "        x = F.dropout(h, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        return torch.softmax(x,dim=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "gkvcIGbmUHGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loader(batch_size):\n",
        "  train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "  val_loader = DataLoader(val_data, batch_size = batch_size, shuffle = True)\n",
        "  test_loader = DataLoader(test_data, batch_size = 1 , shuffle = True)\n",
        "\n",
        "  return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "_wAw8eIlUHE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Roc_curve(labels, preds, model_name):\n",
        "  fpr, tpr, thresholds = roc_curve(labels, preds)\n",
        "  plt.figure(figsize = (4,4))\n",
        "  plt.plot(fpr, tpr)\n",
        "  plt.title(f\"{model_name}\")\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])"
      ],
      "metadata": {
        "id": "YFp6ycsSUHDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_classification_report_txt(report_str, model_name, file_path):\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(f\"Classification Report for {model_name}:\\n\")\n",
        "        f.write(report_str)"
      ],
      "metadata": {
        "id": "U5I_oXVJUHB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def Confusion_matrix(confmat, model_name):\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(4, 4))\n",
        "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "    for i in range(confmat.shape[0]):\n",
        "        for j in range(confmat.shape[1]):\n",
        "            ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "\n",
        "\n",
        "    ax.set_xticklabels(['']+['Not Seizure', 'Seizure'])\n",
        "    ax.set_yticklabels(['']+['Not Seizure', 'Seizure'])\n",
        "\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f\"{model_name}\")\n",
        "    # ax.xaxis.set_label_position('top')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def c_matplot(model, test_loader, j):\n",
        "  all_labels = []\n",
        "  all_preds = []\n",
        "  model_name = type(model).__name__\n",
        "  #model.eval()\n",
        "  #with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    data.x = data.x.to(device)\n",
        "    data.edge_index = data.edge_index.to(device)\n",
        "    data.batch = data.batch.to(device)\n",
        "    data.y = data.y.to(device)\n",
        "\n",
        "    out = model(data.x, data.edge_index, data.batch)\n",
        "    out = out.squeeze()\n",
        "    out = (out >= 0.5).int()\n",
        "    out = out.view(-1).detach().cpu().numpy()\n",
        "    all_labels.extend(data.y.cpu().numpy())\n",
        "    all_preds.extend(out)\n",
        "\n",
        "  clf_rp = classification_report(all_labels, all_preds)\n",
        "  save_classification_report_txt(clf_rp, model_name, f'/content/drive/MyDrive/Classification_reports/exp{j}_{model_name}.txt')\n",
        "  conf = confusion_matrix(y_true = all_labels, y_pred = all_preds)\n",
        "  roc_curve = Roc_curve(all_labels, all_preds, model_name)\n",
        "  return Confusion_matrix(conf, model_name),print(clf_rp), roc_curve\n"
      ],
      "metadata": {
        "id": "ye-N9S5GUHAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, lr, epochs,i):\n",
        "  criterion = torch.nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "  epochs = epochs\n",
        "  model.train()\n",
        "\n",
        "  train_accuracies = []\n",
        "  val_accuracies = []\n",
        "  best_val_acc = 0\n",
        "  best_model_state = None\n",
        "  for epoch in range(epochs+1):\n",
        "    total_loss = 0\n",
        "    acc = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "\n",
        "    for data in loader:\n",
        "      data.x = data.x.to(device)\n",
        "      data.edge_index = data.edge_index.to(device)\n",
        "      data.y = data.y.to(device).float()\n",
        "      data.batch = data.batch.to(device)\n",
        "      #data.y = data.y.view(-1,1)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      out = model(data.x, data.edge_index, data.batch)\n",
        "      out = out.view(-1)\n",
        "      #print(\"Before view\", out)\n",
        "      loss = criterion(out, data.y)\n",
        "      total_loss += loss/ len(loader)\n",
        "      acc += accuracy(out, data.y)/len(loader)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    val_loss, val_acc = test(model, val_loader)\n",
        "    val_accuracies.append(val_acc )\n",
        "\n",
        "    #print(len(train_accuracies),len(val_accuracies))\n",
        "    if val_acc > best_val_acc:\n",
        "      best_val_acc = val_acc\n",
        "      best_train_acc = acc\n",
        "      best_epoch = epoch\n",
        "      best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "    train_accuracies.append(round(acc*100,2))\n",
        "   # total_loss /= len(loader)\n",
        "   # acc /= len(loader)\n",
        "\n",
        "\n",
        "    if(epoch % 5 == 0):\n",
        "      print(f'Epoch {epoch:>3} | Train Loss: {total_loss:.2f} | Train Acc: {acc*100:>.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc:.2f}%')\n",
        "    #print(len(val_accuracies), len(train_accuracies))\n",
        "\n",
        "\n",
        "  model_name = type(model).__name__\n",
        "\n",
        "  torch.save(best_model_state, f'/content/drive/MyDrive//exp{i}_{model_name}.pth')\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  plt.plot(range(epochs + 1), train_accuracies, label='Training Accuracy')\n",
        "  plt.plot(range(epochs + 1), val_accuracies, label='Validation Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.title(f'Training vs. Validation Accuracy of {model_name}')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  #return model, best_val_acc, best_train_acc, best_epoch\n",
        "  return model, round(best_train_acc * 100, 2), round(best_val_acc * 100, 2), best_epoch\n",
        "@torch.no_grad()\n",
        "def test(model, loader):\n",
        "  criterion = torch.nn.BCELoss()\n",
        "  #model.eval()\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "\n",
        "  for data in loader:\n",
        "    data.x = data.x.to(device)\n",
        "    data.edge_index = data.edge_index.to(device)\n",
        "    data.y = data.y.to(device).float()\n",
        "    data.batch = data.batch.to(device)\n",
        "\n",
        "    out = model(data.x, data.edge_index, data.batch)\n",
        "    # print(\"Output shape:\", out.shape)\n",
        "    # print(\"Target shape:\", data.y.shape)\n",
        "\n",
        "    out = out.view(-1)\n",
        "\n",
        "    loss += criterion(out, data.y.float())/len(loader)\n",
        "    acc  += accuracy(out, data.y)/len(loader)\n",
        "\n",
        "  return loss, round(acc *100, 2)\n",
        "\n",
        "\n",
        "def accuracy(pred_y, y):\n",
        "  #print(\"Before Squeeze\", pred_y)\n",
        "  pred = pred_y.squeeze()\n",
        "  #print(\"After Squeeze\", pred)\n",
        "  pred = (pred >= 0.5).float()\n",
        "  #print(\"After thresholding\", pred)\n",
        "  return (pred == y).sum().item()/len(y)\n",
        "\n",
        "# Logs:\n",
        "# the validation accuracy has been pushed to the epoch for loop, have to run the models again and check how the metrics are changing.\n",
        "# Check if the best model is the one that is being returned.\n",
        "# Perform all three experiments with the learning rate set to 0.01\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l0GghSeWUG-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_loader, val_loader, test_loader = loader(batch_size = batch_size)\n",
        "sage  = GraphSAGE(dim_h = 128, num_classes=3).to(device)\n",
        "model = sage\n",
        "model, train_acc, val_acc, epochs = train(model, train_loader, lr = 0.01, epochs = 1, i = 1)\n",
        "test_loss, test_acc = test(model, test_loader)\n",
        "\n",
        "\n",
        "print(f'Test Loss: {test_loss} | Test Acc: {test_acc}%')\n",
        "print(f'Training Accuracy: {train_acc}| Validation Accuracy: {val_acc}| Epoch: {epochs}')"
      ],
      "metadata": {
        "id": "rNJXn-iaUPuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QD7rYPedUPrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9r7xCOtUPqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7pZ-MdxUPoP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}